{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WDoGA-DRIjY"
      },
      "source": [
        "# Hands on Lab - Bagging, Boosting and Stacking\n",
        "\n",
        "**2022 [FinanceData.KR](http://financedata.kr) | [facebook.com/financedata](http://facebook.com/financedata)**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mlxtend 업그레이드 설치 필요\n",
        "!pip install -U mlxtend"
      ],
      "metadata": {
        "id": "TNnHW5WwE4z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgaVxQGWeVbX"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0ZUcCGlRIja"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (14,4)\n",
        "plt.rcParams['lines.linewidth'] = 2\n",
        "plt.rcParams[\"axes.grid\"] = True\n",
        "\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.rcParams[\"axes.formatter.useoffset\"] = False\n",
        "plt.rcParams[\"axes.formatter.limits\"] = -10000, 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuN4F5jnRIjg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-6_MZi5c72I"
      },
      "source": [
        "## 데이터 준비 make_moons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg2qyuZORIjm"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnJNiVLoRIjr"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html\n",
        "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
        "\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5INERFYkRIjx"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "log_clf = LogisticRegression(random_state=42)\n",
        "rnd_clf = RandomForestClassifier(random_state=42)\n",
        "svm_clf = SVC(probability=True, random_state=42)\n",
        "\n",
        "estimators=[('lr', log_clf),('rf', rnd_clf),('svc', svm_clf)]\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4itlKXgRIj3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JJv35EdRIj6"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF372d_7RIj7"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "        DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
        "        max_samples=100, bootstrap=True, n_jobs=-1, random_state=42\n",
        "    )\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "print('BaggingClassifier : ', accuracy_score(y_test, y_pred))\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "print('DecisionTreeClassifier : ', accuracy_score(y_test, y_pred_tree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1gBXIyRIj_"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap, linewidth=10)\n",
        "    if contour:\n",
        "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
        "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
        "\n",
        "plt.figure(figsize=(11,4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.title(\"Decision Tree\", fontsize=14)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(bag_clf, X, y)\n",
        "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSejfyNjRIkD"
      },
      "source": [
        "### Out-of-bag evaluation\n",
        "훈련에 사용하지 않는 데이터로 테스트하도록 지정(oob_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_cXLM2RIkE"
      },
      "source": [
        "# Out-of-bag evaluation\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True, random_state=40\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3vMNQnnRIkH"
      },
      "source": [
        "## RandomForestClassifier()\n",
        "* n_estimators: 트리갯수\n",
        "* max_leaf_nodes: 최대 리프 노드 (과적합 방지)\n",
        "* n_jobs: 병렬처리 개수 (-1=모든 프로세서 사용)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itezS1GaRIkI"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "random_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_clf.predict(X_test)\n",
        "accuracy_score(y_pred, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIgPRxLRIkM"
      },
      "source": [
        "# Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vx4unXGRIkO"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=2)\n",
        "ada_clf = AdaBoostClassifier(clf, n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "plot_decision_boundary(ada_clf, X, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LixbgRxcRIkU"
      },
      "source": [
        "## StackingClassifier\n",
        "http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/\n",
        "       \n",
        "* classifiers: 분류기 리스트\n",
        "* meta_classifier: 다른 분류기의 결과를 학습하는 분류기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtqUbWvhRIkZ"
      },
      "source": [
        "# Simple Stacked Classification\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data[:, 1:3], iris.target\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import numpy as np\n",
        "\n",
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)\n",
        "\n",
        "estimator_names = ['KNN', 'Random Forest', 'Naive Bayes', 'StackingClassifier']\n",
        "\n",
        "print('3-fold cross validation:\\n')\n",
        "for clf, label in zip([clf1, clf2, clf3, sclf], estimator_names):\n",
        "    scores = model_selection.cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl56LC3NRIkc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.gridspec as gridspec\n",
        "import itertools\n",
        "\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "\n",
        "estimator_names = ['KNN', 'Random Forest', 'Naive Bayes', 'StackingClassifier']\n",
        "for clf, lab, grd in zip([clf1, clf2, clf3, sclf], estimator_names, itertools.product([0, 1], repeat=2)):\n",
        "\n",
        "    clf.fit(X, y)\n",
        "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
        "    plt.title(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENFAiCURIkj"
      },
      "source": [
        "**2018-2022 [FinanceData.KR](http://financedata.kr) | [facebook.com/financedata](http://facebook.com/financedata)**\n"
      ]
    }
  ]
}